{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1SIiqKMAEr7MPomEzKnaZsLiIvlC7qgdn",
      "authorship_tag": "ABX9TyNVHqLoPLn02bLONZK7dgTf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/havihaviplants/Artbox/blob/main/%EC%8B%A0%EA%B2%BD%EB%A7%9D_%ED%95%99%EC%8A%B5_%EB%B0%A9%EB%B2%95.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcMtrAghnS8a",
        "outputId": "0775f795-0c1d-4dc7-ec2f-31a172ce4129"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28) (60000,) (10000, 28, 28) (10000,)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# 자신의 Google Drive 마운트하는 코드를 추가하자!\n",
        "mnist = np.load('/content/drive/MyDrive/MY Drive/mnist.npz')\n",
        "x_train = (mnist['x_train'] - np.mean(mnist['x_train'])) / np.std(mnist['x_train'])\n",
        "y_train = mnist['y_train']\n",
        "x_test = (mnist['x_test'] - np.mean(mnist['x_train'])) / np.std(mnist['x_train'])\n",
        "y_test = mnist['y_test']\n",
        "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# Train Data Set\n",
        "train_dataset = TensorDataset(torch.FloatTensor(x_train), torch.LongTensor(y_train))\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
        "\n",
        "# Test Data Set\n",
        "test_dataset = TensorDataset(torch.FloatTensor(x_test), torch.LongTensor(y_test))\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0)"
      ],
      "metadata": {
        "id": "5Sv8qxyhoLnW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU 사용 여부 확인\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6wijuR6oPpf",
        "outputId": "84eaa116-1d41-458a-95c0-15302454ba35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        " def __init__(self):\n",
        "  super().__init__()\n",
        "  self.fc1 = nn.Linear(28*28, 512, bias=True)\n",
        "  self.fc2 = nn.Linear(512, 512, bias=True)\n",
        "  self.fc3 = nn.Linear(512, 512, bias=True)\n",
        "  self.fc4 = nn.Linear(512, 512, bias=True)\n",
        "  self.fc5 = nn.Linear(512, 10, bias=True)\n",
        " def forward(self, x):\n",
        "  x = F.relu(self.fc1(x)) # layer 1\n",
        "  x = F.relu(self.fc2(x)) # layer 2\n",
        "  x = F.relu(self.fc3(x)) # layer 3\n",
        "  x = F.relu(self.fc4(x)) # layer 4\n",
        "  x = self.fc5(x) # layer 5\n",
        "  return x"
      ],
      "metadata": {
        "id": "Mk0PxHjdoSQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import SGD\n",
        "\n",
        "model = MLP().to(device)\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "opti = SGD(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "DnZ70z_Uody_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch = 10\n",
        "losses = []\n",
        "\n",
        "for i in range(epoch):\n",
        " correct = 0\n",
        " for data, target in train_dataloader:\n",
        "  data = data.view(-1, 28*28).to(device)\n",
        " target = target.to(device)\n",
        "\n",
        " output = model(data)\n",
        " loss = criterion(output, target)\n",
        " opti.zero_grad() # gradients을 0으로 초기화\n",
        " loss.backward() # backpropagation으로 gradients 계산\n",
        " opti.step() # gradients 업데이트\n",
        " pred = output.max(1, keepdim=True)[1]\n",
        " correct += pred.eq(target.view_as(pred)).sum().item()\n",
        " print(100.0 * correct / len(train_dataloader.dataset))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbni2OR5oiqo",
        "outputId": "f6f1347b-38d9-4e58-efc3-e721514af7ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0033333333333333335\n",
            "0.0016666666666666668\n",
            "0.0033333333333333335\n",
            "0.005\n",
            "0.008333333333333333\n",
            "0.008333333333333333\n",
            "0.008333333333333333\n",
            "0.0016666666666666668\n",
            "0.0033333333333333335\n",
            "0.0033333333333333335\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "\n",
        "for data, target in test_dataloader:\n",
        " data = data.view(-1, 28*28).to(device)\n",
        " target = target.to(device)\n",
        " output = model(data)\n",
        " pred = output.max(1, keepdim=True)[1]\n",
        " correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "print(100.0 * correct / len(test_dataloader.dataset))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRId0NtIorAv",
        "outputId": "154d0d31-0c03-4097-e4b7-2e63aa993028"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10.24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        " def __init__(self):\n",
        "  super().__init__()\n",
        "  self.fc1 = nn.Linear(28*28, 512, bias=False)\n",
        "  self.fc2 = nn.Linear(512, 512, bias=False)\n",
        "  self.fc3 = nn.Linear(512, 10, bias=False)\n",
        "  self.bn1 = nn.BatchNorm1d(512)\n",
        "  self.bn2 = nn.BatchNorm1d(512)\n",
        "\n",
        "  self.dropout1 = nn.Dropout(0.2)\n",
        "  self.dropout2 = nn.Dropout(0.2)\n",
        " def forward(self, x):\n",
        "  x = F.relu(self.bn1(self.fc1(x))) # layer 1\n",
        "  x = self.dropout1(x)\n",
        "  x = F.relu(self.bn2(self.fc2(x))) # layer 2\n",
        "  x = self.dropout2(x)\n",
        "  x = self.fc3(x) # layer 3\n",
        "  return x\n"
      ],
      "metadata": {
        "id": "X0mgCQxm3KEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch = 20\n",
        "model.train() # 학습 모드로 변경\n",
        "for i in range(epoch):\n",
        " correct = 0\n",
        " for data, target in train_dataloader:\n",
        "  data = data.view(-1, 28*28).to(device)\n",
        "  target = target.to(device)\n",
        "\n",
        " output = model(data)\n",
        " loss = criterion(output, target)\n",
        " opti.zero_grad() # gradients을 0으로 초기화\n",
        " loss.backward() # backpropagation으로 gradients 계산\n",
        " opti.step() # gradients 업데이트\n",
        " pred = output.max(1, keepdim=True)[1]\n",
        " correct += pred.eq(target.view_as(pred)).sum().item()\n",
        " print(100.0 * correct / len(train_dataloader.dataset))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GZJULFl3Srd",
        "outputId": "04d653e2-7dfd-423e-95e1-6ea1d36143cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.005\n",
            "0.005\n",
            "0.0033333333333333335\n",
            "0.01\n",
            "0.0033333333333333335\n",
            "0.0016666666666666668\n",
            "0.008333333333333333\n",
            "0.0033333333333333335\n",
            "0.006666666666666667\n",
            "0.005\n",
            "0.005\n",
            "0.015\n",
            "0.005\n",
            "0.01\n",
            "0.006666666666666667\n",
            "0.008333333333333333\n",
            "0.01\n",
            "0.005\n",
            "0.005\n",
            "0.006666666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "model.eval() # 평가(테스트) 모드로 변경\n",
        "for data, target in test_dataloader:\n",
        " data = data.view(-1, 28*28).to(device)\n",
        " target = target.to(device)\n",
        " output = model(data)\n",
        " pred = output.max(1, keepdim=True)[1]\n",
        " correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "print(100.0 * correct / len(test_dataloader.dataset))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABcuZgRa3a-0",
        "outputId": "8940d9f9-a3d0-43da-c61a-532bccec49b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10.31\n"
          ]
        }
      ]
    }
  ]
}